{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Logistic Regression\n",
    "## One vs. All\n",
    "\n",
    "### What it is?\n",
    "The previous tutorial on [Logistic Regression](3_BinaryLogisticRegression.ipynb) was about binary output, so the input could belong to class 0 or 1, but that's not very useful because plenty of times the range of classes is greater than two. Here is where this approach fits, it's a generalization of the Binary Logistic Regression so that it can be applied to any number of output classes.\n",
    "\n",
    "Its name comes from the fact that in order to generalize the model, we create as many \"mini-models\" as classes and we train each one to identify only one class, so when it sees an input, it knows if it belongs to that class or not, but knows nothing about the other classes. ![From Binary to Multiclass Logistic Regression](https://houxianxu.github.io/images/logisticRegression/4.png)\n",
    "\n",
    "More formally speaking, we have an input $x \\in \\mathbb{R}^n$ and a output $y \\in \\mathbb{R}^m$, with $m$ being the number of output classes. The output vector contains a 1 in the position where the class that it belongs to is associated. In the case of the MNIST dataset, a label could be: $y = \\text{[0 0 0 1 0 0 0 0 0 0]}$ to indicate that it's the digit three. What we do is train $m$ \"mini-models\" that can say if an input, for example, is a 3 or not, but in the case that it's not a 3, it doesn't know which digit it is.\n",
    "\n",
    "At the end, the predicted output is the one \"mini-model\" whose output probability is the greatest. ![Prediction Multiclass Logistic Regression](https://www.pugetsystems.com/pic_disp.php?id=43182)\n",
    "\n",
    "###  General explanation of notebook\n",
    "The structure of the notebook is getting all the data and a simple visualization. Later, we will use the scikit-learn library implementation of Logistic Regression. Finally, we will go through the mathematical explanation of this One vs. All generalization and implement it from scratch to compare it.\n",
    "\n",
    "### 1. Getting the data\n",
    "First of all, we have to import all of the dependencies that we will use to retrieve the data, clean it and also visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np #library to work with vectors and matrix\n",
    "import matplotlib.pyplot as plt #library to work with graphics and plots\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the famous MNIST dataset, since it contains handritten digits (from 0 to 9) that will represent the 10 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mnist(path=None):\n",
    "    r\"\"\"Return (train_images, train_labels, test_images, test_labels).\n",
    "\n",
    "    Args:\n",
    "        path (str): Directory containing MNIST. Default is\n",
    "            /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist.\n",
    "            Create if nonexistant. Download any missing files.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_images, train_labels, test_images, test_labels), each\n",
    "            a matrix. Rows are examples. Columns of images are pixel values.\n",
    "            Columns of labels are a onehot encoding of the correct class.\n",
    "    \"\"\"\n",
    "    #Taken from: 'https://mattpetersen.github.io/load-mnist-with-numpy'\n",
    "    import gzip\n",
    "    import os\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "    url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "    files = ['train-images-idx3-ubyte.gz',\n",
    "             'train-labels-idx1-ubyte.gz',\n",
    "             't10k-images-idx3-ubyte.gz',\n",
    "             't10k-labels-idx1-ubyte.gz']\n",
    "\n",
    "    if path is None:\n",
    "        # Set path to /home/USER/data/mnist or C:\\Users\\USER\\data\\mnist\n",
    "        path = os.path.join(os.path.expanduser('~'), 'data', 'mnist')\n",
    "\n",
    "    # Create path if it doesn't exist\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Download any missing files\n",
    "    for file in files:\n",
    "        if file not in os.listdir(path):\n",
    "            urlretrieve(url + file, os.path.join(path, file))\n",
    "            print(\"Downloaded %s to %s\" % (file, path))\n",
    "\n",
    "    def _images(path):\n",
    "        \"\"\"Return images loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 16 bytes are magic_number, n_imgs, n_rows, n_cols\n",
    "            pixels = np.frombuffer(f.read(), 'B', offset=16)\n",
    "        return pixels.reshape(-1, 784).astype('float32') / 255\n",
    "\n",
    "    def _labels(path):\n",
    "        \"\"\"Return labels loaded locally.\"\"\"\n",
    "        with gzip.open(path) as f:\n",
    "            # First 8 bytes are magic_number, n_labels\n",
    "            integer_labels = np.frombuffer(f.read(), 'B', offset=8)\n",
    "\n",
    "        def _onehot(integer_labels):\n",
    "            \"\"\"Return matrix whose rows are onehot encodings of integers.\"\"\"\n",
    "            n_rows = len(integer_labels)\n",
    "            n_cols = integer_labels.max() + 1\n",
    "            onehot = np.zeros((n_rows, n_cols), dtype='uint8')\n",
    "            onehot[np.arange(n_rows), integer_labels] = 1\n",
    "            return onehot\n",
    "\n",
    "        return _onehot(integer_labels)\n",
    "\n",
    "    train_images = _images(os.path.join(path, files[0]))\n",
    "    train_labels = _labels(os.path.join(path, files[1]))\n",
    "    test_images = _images(os.path.join(path, files[2]))\n",
    "    test_labels = _labels(os.path.join(path, files[3]))\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images, train_labels, test_images, test_labels = mnist(\"../datasets/MNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of the structure of the outputs, a vector $y$ with a 1 matching the position of the sample in the training set that match that class and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function transforms the previous vector, also called one-hot vector, to the real digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_one_hot_to_vector(labels):\n",
    "    return np.argmax(labels, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "After load the MNIST dataset, it's always a good idea to visualize the dataset and how it is composed. \n",
    "Each image is composed of 768 attributes, each one representing a pixel from a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_number_image(image, label):\n",
    "        r\"\"\"Plots the handwritten image in a matplotlib figure\n",
    "\n",
    "        Args:\n",
    "            image: NumPy array with the values of an image from the MNIST dataset.\n",
    "                    It should be 28x28 pixels each one.\n",
    "                    \n",
    "            label: Scalar with the label (a number, not a one hot vector) of the image\n",
    "        \"\"\"\n",
    "        # Make those columns into a array of 8-bits pixels\n",
    "        # This array will be of 1D with length 784\n",
    "        # The pixel intensity values are float from 0 to 1\n",
    "        # Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "        pixels = image.reshape((28, 28))\n",
    "\n",
    "        # Plot\n",
    "        plt.title('Label is {}'.format(label))\n",
    "        plt.imshow(pixels, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85b6ec3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f85b6ec3c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_number_image(train_images[0], train_labels[0])\n",
    "plot_number_image(train_images[1], train_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see the image, which is represented by an input vector of 784 dimensions (28x28 pixels, each pixel a value) with range 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MultiClass Logistic Regresssion with Scikit-learn \n",
    "In order to get a general idea of the result of MultiClass Logistic Regression, learn how to use a powerful library and later compare it with our algorithm, we are going first to do it with the scikit-learn implementation.\n",
    "\n",
    "It's very easy to use and with only 2 lines, we can have a functional model already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9263\n",
      "CPU times: user 28.4 s, sys: 245 ms, total: 28.7 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = linear_model.LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "logreg.fit(train_images, from_one_hot_to_vector(train_labels)) \n",
    "\n",
    "Y_pred = logreg.predict(test_images)\n",
    "acc = accuracy_score(from_one_hot_to_vector(test_labels), Y_pred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the results, there are two important points. First, the accuracy that it's quite high with $92.63$ in the test dataset. In addition, we can see that with the increase in the model complexity (from linear regression to logistic regression multiclass), the training time increases too, now it lasts 30 seconds to get the model trained.\n",
    "\n",
    "### 3. MultiClass Logistic Regression implementation explained\n",
    "As stated before, this is a generalization of the Binary Logistic Regression by creating as many \"mini-models\" as classes and choose the class with the most probability. For that reason, most of the functions are the same in the Multiclass Logistic Regression and in the Binary Logistic Regression. First of all, the sigmoid function: $\\sigma(z) = \\frac{1}{1+e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the sigmoid function accepts one parameter, $z$ which is the ouput of the linear transformation of the inputs, so finally, the whole function for Logistic Regression is: $\\frac{1}{1+e^{-\\sum_{i=1}^{n}x_i \\theta_i}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logisticRegression(X, theta):\n",
    "    return sigmoid(X@theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that the model is defined, we have to find the cost function of the model, to know how well the model performs. To increase the performance, we will try to minimize the cost function by Gradient Descent. As before, we will use the same cost function: $\\sum_{i=1} ylog(\\hat{y})+(1-y)log(1-\\hat{y}) +\\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_j^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costFunction(X, Y, theta, lam):\n",
    "    z = X@theta\n",
    "    h = sigmoid(z)\n",
    "    return (1/X.shape[0])*(-Y.T@np.log(h)-(1-Y).T@np.log(1-h)+(lam/2)*theta.T@theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to minimize the cost function, we will use Gradient Descent. ![Gradient Descent Pseudocode](https://cdn-images-1.medium.com/max/1040/1*oJKalifbWzwuo3fRjWJjTg.png) From the pseudocode, we see that the derivative of the cost function with respect to the $\\theta$ parameter. This has been calculated in the [Binary Logistic Regression](3_BinaryLogisticRegression.ipynb) and is $gradient = \\frac{1}{m}\\sum_{i=1}^m x^i (\\hat{y}_i - y_i) \\frac{\\lambda}{m}\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(X, y, theta, lr, lam):\n",
    "    z = np.dot(X, theta)\n",
    "    h = sigmoid(z)\n",
    "    new_theta = theta\n",
    "    new_theta[0] = 0\n",
    "    gradient = (np.dot(X.T, (h - y))+lam*new_theta) / y.size\n",
    "    return theta - lr * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all the function needed to train the model so it can predict which number is from the image. Now, another simple function more to calculate the accuracy of the model, it takes the input, the $\\theta$ parameter and the true label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, Y, theta):\n",
    "    pred = logisticRegression(X, theta).argmax(axis=1)\n",
    "    boolarr = pred == Y\n",
    "    return np.sum(boolarr) / boolarr.size    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point, everythin is similar to the Binary Logistic Regression. Now, what it changes is the parameters that have to be trained. Instead of a column vector, with as many attributes of the parameters as the input, we will expand this to create a matrix $m$x$n$ with $m$ being the number of input's attributes and $n$ being the number of output classes, creating the $n$ mini-models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 784\n",
      "n = 10\n"
     ]
    }
   ],
   "source": [
    "print(\"m = {}\".format(train_images.shape[1]))\n",
    "print(\"n = {}\".format(train_labels.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the previous notebooks, we haven't talked at all about the learning rate ($lr$) and which impact does it have in the traing. For this reason, here we are going to create three instances of our model and each one will train with a different learing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta1 = np.zeros((train_images.shape[1], train_labels.shape[1])) #the three instances\n",
    "theta2 = theta1\n",
    "theta3 = theta1\n",
    "lr = [0.1, 0.03, 0.01] #the three different learning rates\n",
    "lam = 1 #the lambda (regularization parameter) will be constant among the instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a later comparison, we will save the cost of each instance for every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "costAccumulated1 = []\n",
    "costAccumulated2 = []\n",
    "costAccumulated3 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 52s, sys: 1min 33s, total: 6min 26s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    theta1 = gradient(train_images, train_labels, theta1, lr[0], lam)\n",
    "    theta2 = gradient(train_images, train_labels, theta2, lr[1], lam)\n",
    "    theta3 = gradient(train_images, train_labels, theta3, lr[2], lam)\n",
    "    costAccumulated1.append(costFunction(train_images, train_labels, theta1, lam).mean())\n",
    "    costAccumulated2.append(costFunction(train_images, train_labels, theta2, lam).mean())\n",
    "    costAccumulated3.append(costFunction(train_images, train_labels, theta3, lam).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several interesting things here: \n",
    "\n",
    "First of all is the amount of time it has taken to train in contrast to the Binary Logistic Regression or the Linear Regression. As the complexity of the model increases, the time for taking increases too and this is due to the growth of computations it has to perform. Remember that this model takes the output of the Linear Regression and squashes it into 0-1 range, adding one more \"layer\" of complexity and the sames with the gradient.\n",
    "\n",
    "The other interesting thing is the .mean() in the costFunction. The reason behind this is that when we calculate the cost, it calculates it for every \"mini-model\" so what it returns is not a single number but a vector with the cost for each \"mini-model\" that represents each \"digit\" of the dataset. There are different ways of converting the vector into a single number like take the sum or the mean, as we have done here.\n",
    "\n",
    "Finally, let's plot the cost function for every instance of the model and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f8592af7c18>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAxafTTtG1ieAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8592bd7588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(1, len(costAccumulated1)+1)]\n",
    "plt.plot(x, costAccumulated1, color='green', label=\"lr 0.1\")\n",
    "plt.plot(x, costAccumulated2, color='red', label=\"lr 0.03\")\n",
    "plt.plot(x, costAccumulated3, color='blue', label=\"lr 0.01\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the learning rate does affect the cost function. In this example, the greater the learing rate, the faster the deacrease of the cost function. This means that the model has the capacity to learn faster and a smaller learning rate slows the training. It's not always the same and in other situation, having the learing rate set to big could make the gradient explode and consequently the model would never converge, but this is another topic.\n",
    "![Exploding Gradients](https://qph.fs.quoracdn.net/main-qimg-ed4a3867ca90b95b33b95f1b89d8335c-c)\n",
    "\n",
    "Reference:\n",
    "1. [Deep Learning Book by Ian Goodfellow and Yoshua Bengio and Aaron Courville](https://www.deeplearningbook.org/)\n",
    "2. [Coursera - Machine Learning](https://www.coursera.org/learn/machine-learning)\n",
    "3. https://en.wikipedia.org/wiki/Multiclass_classification\n",
    "4. https://www.codeproject.com/Articles/821347/MultiClass-Logistic-Classifier-in-Python\n",
    "5. https://www.pugetsystems.com/labs/hpc/Machine-Learning-and-Data-Science-Multinomial-Multiclass-Logistic-Regression-1007/\n",
    "6. https://houxianxu.github.io/2015/04/23/logistic-softmax-regression/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
